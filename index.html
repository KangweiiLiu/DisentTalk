<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D-DiffuBindTalk</title>
    <style>
        /* Modern and clean styling */
        :root {
            --primary-color: #2c3e50;
            --secondary-color: #3498db;
            --background-color: #f9f9f9;
            --text-color: #333;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: var(--background-color);
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
        }

        h1 {
            color: var(--primary-color);
            font-size: 2.5em;
            margin-bottom: 20px;
        }

        h2 {
            color: var(--primary-color);
            border-bottom: 2px solid var(--secondary-color);
            padding-bottom: 10px;
            margin-top: 30px;
        }

        h3 {
            color: var(--primary-color);
            margin-top: 25px;
        }

        .author-info {
            font-style: italic;
            color: #666;
            margin-bottom: 20px;
        }

        .abstract {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        .grid-container {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .grid-item {
            background: white;
            padding: 15px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        video {
            width: 60%;
            border-radius: 4px;
            margin-bottom: 10px;
        }

        em {
            display: block;
            text-align: center;
            color: #666;
            margin-top: 10px;
        }

        img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
        }

        .citation {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-top: 30px;
        }
        /* 在之前的style标签中添加以下样式 */
        .grid-container video {
            margin-bottom: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            transition: transform 0.3s ease;
        }

        .grid-container video:hover {
            transform: scale(1.02);
        }

        .grid-item {
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        .grid-item em {
            margin-top: 15px;
            font-size: 0.9em;
            color: #666;
            text-align: center;
            width: 100%;
        }

        /* 添加响应式视频容器 */
        @media (max-width: 768px) {
            .grid-container {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>DisentTalk: Cross-lingual Talking Face Generation via Semantic Disentanglement Diffusion</h1>
        <div class="author-info">
            <p>Kangwei Liu, Junwu Liu, Yun Cao, Jinlin Guo, Xiaowei Yi</p>
            <p>Accepted by ICME 2025</p>
        </div>
    </div>

    <div class="abstract">
        <h2>Abstract</h2>
        <p>Existing diffusion-based audio-driven talking face generation methods often suffer from poor lip synchronization and unnatural facial expressions, with these issues being particularly pronounced in cross-lingual scenarios. These performance issues stem from two fundamental scientific challenges: the semantic entanglement of facial intermediate representations (e.g., 3DMM parameters) and the isolated processing of spatial-temporal features. To address these challenges, we present a novel framework with two key innovations: (1) a data-driven semantic disentanglement approach that decomposes 3DMM parameters into meaningful subspaces for fine-grained facial region control, and (2) a hierarchical diffusion architecture with region-aware attention that jointly models spatial-temporal features throughout generation. We further introduce CHDTF, a Chinese high-definition talking face dataset for cross-lingual evaluation. Extensive experiments demonstrate that our method outperforms existing approaches, achieving superior lip synchronization and natural expressions while maintaining temporal coherence.</p>
    </div>

    <h2>Method Overview</h2>
    <div class="grid-container">
        <div class="grid-item">
            <img src="framework.jpg" alt="Framework Overview">
        </div>
    </div>

    <h2>Supplementary Video Materials</h2>

    <h3>Introduction Video in Different Languages</h3>
    <div class="grid-container">
        <div class="grid-item">
            <video controls>
                <source src="Intro/art_intro_English.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="Intro/art_intro_Chinese.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="Intro/art_intro_Japan.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="Intro/art_intro_Spanish.mp4" type="video/mp4">
            </video>
            <em>Introduction Videos in Different Languages</em>
        </div>
    </div>

    <h3>Comparison of Different Methods (HDTF dataset)</h3>
    <div class="grid-container">
        <div class="grid-item">
            <video controls>
                <source src="HDTF/algorithm_comparison_rd_radio53_crop_256_000.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="HDTF/algorithm_comparison_wda_chrisvanhollen1_crop_256_000.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="HDTF/algorithm_comparison_wra_mikecrapo_crop_256_000.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="HDTF/algorithm_comparison_wra_vickyhartzler_crop_256_000.mp4" type="video/mp4">
            </video>
            <em>Comparison of Different Methods (HDTF dataset)</em>
        </div>
    </div>

    <h3>Comparison of Different Methods (CHDTF dataset)</h3>
    <div class="grid-container">
        <div class="grid-item">
            <video controls>
                <source src="CHDTF/algorithm_comparison_baoxiaofeng_187_crop_0_260.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="CHDTF/algorithm_comparison_kanghui_18_crop_0_200.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="CHDTF/algorithm_comparison_lizimeng_169_crop_0_300.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="CHDTF/algorithm_comparison_yanyuxin_36_crop_0_300.mp4" type="video/mp4">
            </video>
            <em>Comparison of Different Methods (CHDTF dataset)</em>
        </div>
    </div>

    <h3>Comparison of Different Methods (Voxceleb2 dataset, multilingual)</h3>
    <div class="grid-container">
        <div class="grid-item">
            <video controls>
                <source src="Vox2/algorithm_comparison_id00343.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="Vox2/algorithm_comparison_id00365.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="Vox2/algorithm_comparison_id00383.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="Vox2/algorithm_comparison_id00416.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="Vox2/algorithm_comparison_id00429.mp4" type="video/mp4">
            </video>
            <video controls>
                <source src="Vox2/algorithm_comparison_id00459.mp4" type="video/mp4">
            </video>
            <em>Comparison of Different Methods (Voxceleb2 dataset, multilingual)</em>
        </div>
    </div>

    <h3>Disentanglement Analysis of 3DMM Parameters</h3>
    <div class="grid-container">
        <div class="grid-item">
            <video controls>
                <source src="show_disentangle/disentagle_videos_.mp4" type="video/mp4">
            </video>
            <em>Demonstration of Disentanglement of 3DMM Parameters</em>
        </div>
    </div>

    <h3>Weight Comparison Experiment</h3>
    <div class="grid-container">
        <div class="grid-item">
            <video controls>
                <source src="ablation_weight/weight_comparison22.mp4" type="video/mp4">
            </video>
            <em>Demonstration of Different Weights Effects</em>
        </div>
    </div>

    <h3>Ablation Study on Different Components</h3>
    <div class="grid-container">
        <div class="grid-item">
            <video controls>
                <source src="ablation_model/Components_comparison_222.mp4" type="video/mp4">
            </video>
            <em>Ablation Study on Different Components</em>
        </div>
    </div>

    <div class="citation">
        <h2>Citation</h2>
        <p>If you find our work useful, please consider citing:</p>
        <!-- Citation details would go here -->
    </div>



</body>
</html>